# COEN 169 Web Information 04_19_16

## Project

  eval_data - preprocessing
  app/src - retrieval models
  trec_eval qrel

## Midterm - May 5th

## Relevance feedback

  Rocchio-Grew = alpha *

  Psuedo-Relevance feedback
    assume first n are relevant

  Iterate over several runs
    usually no more than 2 iterations

  Implicit/indirect feedback

## VSM

    1) Vocabular
      + Tokenization
      + Stemming
      + Removing Stopwords
    2) Text representation
      + Binary
      + TF
      + TF.IDF
      + Okapi
    3) Similarity Computation
      + Inner product
      + cosine
      + Euclidean distance
      + sim(d, f)

    - vector space is not very efficient
    - V (LSI) -> reduce to size n
      - give a new coordinate system
      - each coordinate represents a linear combination of previous coordinates
      - Translate to new coordinates
      - Word2Vector
        - Deep learning
      - king-queen
        - man-woman

## Query Expansion/Suggestion

    - Dictionary - define phrases, relations between words
    - Statistical
    - Binary, etc
    - matrix A
    - C = A(A_T)
    - C_ij = t_i * t_j
      - # of docs containning both therms i & j
      - measure of similarity between the two terms
      - Co-occurance Matrix
      - Term-Term
    - D = A_T(A)
    - D_ij =
      - + of terms appearing in both doc i & j
      - Doc-Doc
      - Similarity between documents

## Statistical Language Modeling

## Discrete Random Variable

    - Let A denote a discrete random variable
    - A is a discrete random variable if
      - A describes an event with a finite number of possible outcomes (this property maeks the random variable discrete)
      - A describes an event whose outcome has some degree of unvertainty (this property makes the variable random)
      - binomial, polynomial, etc

  Examples

    A = it will rain tomorrow
    A = the coin-flip will show head
    A = you will win the lottery in your lifetime

## What is a probability distribution

    - Probability distributino gives the probability of each possible outcome of a random variable
    - Two conditions must be fulfilled

## What can we do with a prob distribution

    - Independent assumptions, compute probability of taking multiple blocks

## Language Modeling

    - Individual or sequnce of words

## Unigram Language Model

    - Define a probability distribution over individual words
    - Estimate (and predict) the likelihood of each word independent of any other word
    - Assumes words are independent
    - Other language models take context into account
    - Sequences of words can be assigned a probability by multiplying individual occurences
    - Two important steps
      - estimation - observing text and estimating the prob of each word
      - prediction - usingthe language model to assign a probability to a span of text
    - Given any query, how can you rank a document?

  Doc
    Q = (w_1,w_2,...,w_q)
    Q=(Santa,clara)
    p(santa|d) \* p(clara|d)

    so
    P(Q|D) = P(w_1|d) \* P(w_2|d) \* ... P(w_q|d)

END
