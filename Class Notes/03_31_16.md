# COEN 169 Web Infrastructure 03_31_16

## Terminologies

  Query

    - representative data of user's information need: text (default) and other media

  Document

    - Data candidate to satisfy user's informatino need: text (default) and other media

  Corpus

    - set of documents
    - for web search, it is the whole web
    - Valuable corpora from **TREC** (Text Retrieval Evaluation Conference)

## Retrieval Models

  Boolean

  Vector space

    - basic vector space
    - extended boolean

  Probabilistic Models

    - statistical language models
    - two poisson model
    - Bayesian inference networks

  Citaion/Link analysis models

    - PageRank
    - Hub & authorities

  LM -> P(alpha|rho)
  Use multiple models

## Boolean queries; Exact match

    - Ask a query that is a boolean expression
    - AND, OR, NOT join query terms
    - No ranking
    - As long as it contains the paramater, they are equally relevant
    - Simplest model, still used/relevant

## Best Match (Document Ranking)

    - Ex: most probabilistic models
    - Query describes the desired retrieval criterion
    - Degree of relevance is a continuous/integral variable; each document matches to some degree
    - Result in a ranked list

## Exact Match vs Best Match

  Best Match

    - more accurate/effective
    - bridge semantic gap
    - doesn't need to be as precise
    - need to look through the rank list

  Exact Match

    - Hard ot define the precise query; too strict

## Combining Various Retrieval Models

    - IN modern search engines, combine large number of ranking symbols
    - Difficult to assign wiehgts

## Web crawler/Spider

  Browses the web: systematically browses and collects web pages

    - Begin with known "seed" URLS
    - Fetch and parse them
      - Extract URLS they point to
      - Place the extracted URLs on a queue
    - Fetch each URL on the queue and repeat

## Text Preprocessing

  Extract representative index Terms

    - Tokenization
      - Western -> spaces, punctuation, capitalization, hyphenation
      - Chinese, Japanes -> more complex word segmentation
    - Remove stopwords (the, is, existing standard list)
    - Morphological analysis (stemming)
      - determine stem form of given inflected forms
    - Other: extract phrases

## Tokenization

    - Analyze text into a sequence of discrete tokens
    - deal with punctuation
    - Case folding: reduce all letters in lower case
    - Simplest approach: ignore all numbers and punctuation and use only case-insensitive
      - unbroken strings of alphabetic characters as tokens

## Stopwords

    - Exclude high-frequency words
      - a, the, in, to
      - pronouns: I, he, she, it
    - Saving space
    - Speeding searches

  Stopwords list

    - for efficiency, store strings for stopwords in hashtable to access in constant time

  Trends in Stopword removal

    - Earliest: 200-300
    - Improve efficiency and effectiveness
    - Very frequent were problematic
    - Latest trend is to index stopwords and (possibly) ignore them at query-time

## Lemmatization

    - Reduce inflectional/variant forms to base form
    - Direct impact on vocabulary size
    - Ex
      - am, are, is -> be
      - car, cars, car's, cars' -> car
      - the boy's cars are different colors -> the boy car be different color
    - How?
      - Need a list of grammatical rules + list of irregular words
      - children-> child, spoken->speak
      - Need to understand the meaning of the word -> saw vs saw

#Stemming

    - Correct morphological analysis is language specific and can be complex
    - Reduce tokens to "root" form o fwords
    - Stemming blindly strips off kown affixes in an iterative fashion

## Typical rules in Porter

    - sses -> ss
    - ies -> i
    - ational -> ate
    - tional -> tion
    - About 30 rules total: porter stemmer
    - Errors
      - Comission
        - organization, organ -> organ
        - police, policy -> polic
        - arm, army -> arm
      - Omission
        - cylinder, cylindrical
        - create, creation
        - Europe, European

## Other Stemmers

    - Lovins (250 rules)
    - Gets expensive to look at words
    - Motivated by linguistics as well as IR
    - Full morphological analysis - modest benefits for retrieval

## Text Representation: Process of indexing

    - What pages contain a keyword
    - Inverted lists
    - Using an index, you don't have to scan all documents
    - Scan all once -> if you know the documents, you know what's in them

  Inverted Lists

    - Common indexing techniques
    - doc-> word, word-> doc
    - look for union between lists

  Bag of Words

    - Simplest
    - Bag that contains words
    - no order

  Phrases

    - Single word/stem indexing may not be sufficient
      - treat as a single token
    - Include phrases (thesaurus classes)
    - Identify phrases:
      - Dictionary
      - Most common N word phrases by corpus statistics
      - analysis, noun phrases
      - More sophisticated algorithm like "hidden markov model"

## Suggestions

    - Tokenization, stopwords, stemming
    - Customized tokenizer for specific domain/application
    - remove stopwords only when you have to
      - like not enough disk space
    - remove stopwrods from the query if they are not part of a phrase
    - stemming depending on the importance of recall and the size of the collection

## Statistical Properties of Text

    - How is the frequency of different words distributed?
    - How fast does vocabulary size grow with the size of a corpus?

## Word Frequency

    - A few words are very common
      - the, of can account for 10% of occurrences
    - Most words very rare
      - Half in a corpus appear only once
    - Heavy tailed distribution, most probablility mass is in the tail
    - 
