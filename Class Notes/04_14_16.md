# COEN 169 Web Infrastructure 04_14_16

## RECAP

    - Vector Space Model (VSM)
      - Represent a document, query, as a vector
      - Use math to measure the difference/relevance of documents and queries

      1) Binary
      2) TF
      3) TF * IDF
          - Term should appear a lot in your document but not in others
          - Could use raw TF
          - Or maybe use log(TF)+1
          - IDF = 1/document frequency
              - = N/DF
              - log(N/DF)
          - Many ways to calculate for both

    - Similarity Metric
        - Inner Product
        - cosine similarity -> need normalized version of inner product
            - (sum of inner products)/(product of lengths of vectors)
        - Euclidian distance
        - alpha^2 = a^2 + b^2 - 2abcos(Theta)
    - L2R

## Multimedia Retrieval

    - Query, Files -> feature extraction

## SMART weigtings

    - Named after IR system
    - Ways to calculate components
      - Still using TF, DF, normalization

## Okapi bm25

    - One of the most popular ranking functions in practice
    - Project will implement this along with other retrieval models

## Query Representation

    - Improving results
      - For high recall, eg. aircraft != plane
    - Options for improving results
      - Local methods
        - Relevance feedback
        - Pseudo relevance feedback

## Relevance feedback

    - User feedback on relevance of docs in initial set of results
      - User issues a query
      - marks some results as relevant or nonrelevant
      - computes better representation based on the feedback
      - relevance feedback can go through multiple iterations
    - Ideal: it may be difficult to formulate a good query when you don't know the collection well
      - Iterate
    - Expand query after feedback

## Query point movement

    - The idea is simply to move the query point so as to get closer to relevant objects
    - Lucene
    - Given a set of vectors, how do you compute the center?
      - d1 + d2 / 2
      - 1/n (d1 + d2 + ... + dn)

## Rochio algorithm

    - The centroid is the mass of a set of popoints
    - 1/abs(C) sum(distances)
    - weights are fixed
    - New query moves toward relevant documents and away from irrelevant documents
    - ex
      - q_0 "java"
      - d_1_t : oop language
      - d_2_t : programming language
      - alpha = 1, beta = 0.5
      - voc : java oop programming language
      - q_0 = (1,0,0,0)
      - d_1_t : (0,1,0,1)
      - d_2_t : (0,0,1,1)
      - d_1_t + d_2_t / 2 = (0,0.5,0.5,1)
      - q_m = 1 * (1,0,0,0) + 0.5 * (0,0.5,0.5,1)
        - = (1,0.25,0.25,0.5)
        - weights

## Relevance Feedback in Vector spaces

    - On initial query
    - We can mdoify the query based on relevance feedback
    - Use only documents that were marked

    - Assumptions
      - User has reasonable knowledge for initial query
      - Relevance prototypes are "well-behaved"
        - Term distribution in relevant documents will be similar
        - Term distribution in non-relevant documents will be different from those in relevant
      - Violations of assumption 2
        - r
    - Problems

## Rule-of-thumb

    - Empirically, one round of relevance feedback is very useful
    - Two rounds is only sometimes marginally useful
      - Having at least 5 judged documents is recommmended

## Excite Relevance Feedback

## Pseudo relevance feedback

    - automates the manual part of true relevance feedback
    - Algorithm
      - retrieve a ranked list of hits for the query
      - Assume that the top k documents are relevant
      - Do relevance feedback (Rocchio)
    - Works very well on average
    - Can go very wrong for some queries
    - Several iterations can cause query drift

## Query Suggestion

    - USers give additional input on documents, reweight terms in the documents
    - Query suggestion, usery give additional input on words or phrases

## Query Assist

## How do we augment the user query

    - Thesaurus
    - Global Analysis
    - Local analysis (dynamic)

END
